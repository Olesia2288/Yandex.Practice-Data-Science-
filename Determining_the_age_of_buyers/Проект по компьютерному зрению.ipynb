{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение возраста покупателей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Краткое описание проекта:\n",
    "\n",
    "Сетевой супермаркет «Хлеб-Соль» внедряет систему компьютерного зрения для обработки фотографий покупателей. Фотофиксация в прикассовой зоне поможет определять возраст клиентов, чтобы:\n",
    "Анализировать покупки и предлагать товары, которые могут заинтересовать покупателей этой возрастной группы;\n",
    "Контролировать добросовестность кассиров при продаже алкоголя.\n",
    "\n",
    "Задача проекта:\n",
    "\n",
    "Построить модель, которая по фотографии определит приблизительный возраст человека. В нашем распоряжении набор фотографий людей с указанием возраста.\n",
    "\n",
    "Необходимо провести исследовательский анализ набора фотографий и подготовить данные к обучению, а также обучить нейронную сеть и рассчитайте её качество (МАЕ должно быть не ниже 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследовательский анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/datasets/faces/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7591 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)                                       \n",
    "train_datagen = datagen.flow_from_dataframe(dataframe=labels,\n",
    "    directory='/datasets/faces/final_files/',   \n",
    "    x_col='file_name',\n",
    "    y_col='real_age',                                         \n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw',\n",
    "    seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выборки: 7591\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер выборки:\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels['real_age'], bins=20, edgecolor='black')\n",
    "plt.xlabel('Возраст')\n",
    "plt.ylabel('Количество')\n",
    "plt.title('Распределение возраста в выборке')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотр 15 первых изображений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15,10))\n",
    "#for i, ax in enumerate(axes.flat):\n",
    "    #img = plt.imread('/datasets/faces/final_files/' + labels.iloc[i]['file_name'])\n",
    "    #ax.imshow(img)\n",
    "    #ax.set_title('Возраст: ' + str(labels.iloc[i]['real_age']))\n",
    "    #ax.axis('off')\n",
    "    #if i == 14:\n",
    "        #break\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: так как в модели больше всего фотографий людей в возрасте от 20 до 40 лет, соответственно именно люди этого возраста будут определены с большей вероятностью правильно, фотографий людей после 60 не слишком много, поэтому модель может ошибиться из-за недостаточного количества данных. Людей, чей возраст больше 80 еще меньше, соответственно ошибка при определении их возраста может быть еще выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Первоначальный код*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "def load_train(path):\n",
    "    labels = pd.read_csv(path + '/labels.csv')\n",
    "    datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 validation_split=0.25,\n",
    "                                 horizontal_flip=True)\n",
    "    train_datagen = datagen.flow_from_dataframe(dataframe=labels,\n",
    "                                                directory=path + '/final_files/',\n",
    "                                                x_col='file_name',\n",
    "                                                y_col='real_age',\n",
    "                                                target_size=(224, 224),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='raw',\n",
    "                                                subset='training',\n",
    "                                                seed=42)\n",
    "    return train_datagen\n",
    "\n",
    "def load_test(path):\n",
    "    labels = pd.read_csv(path + '/labels.csv')\n",
    "    datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 validation_split=0.25,\n",
    "                                 horizontal_flip=True)\n",
    "    test_datagen = datagen.flow_from_dataframe(dataframe=labels,\n",
    "                                               directory=path + '/final_files/',\n",
    "                                               x_col='file_name',\n",
    "                                               y_col='real_age',\n",
    "                                               target_size=(224, 224),\n",
    "                                               batch_size=32,\n",
    "                                               class_mode='raw',\n",
    "                                               subset='validation',\n",
    "                                               seed=42)\n",
    "    return test_datagen\n",
    "   \n",
    "\n",
    "def create_model():\n",
    "    resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation=None))\n",
    "    model.compile(loss='mae', optimizer=tf.keras.optimizers.Adam(lr=0.0001), metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=None, epochs=5,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "        \n",
    "    model.fit(train_data, \n",
    "              validation_data=test_data, \n",
    "              batch_size=batch_size, \n",
    "              epochs=epochs, \n",
    "              steps_per_epoch=steps_per_epoch, \n",
    "              validation_steps=validation_steps, \n",
    "              verbose=2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарий к правке первоначального кода:**\n",
    "- аугментацию в тестовой выборке убрала;\n",
    "- МАЕ использовала намеренно, так как в контексте задачи, модель будет минимизировать именно МАЕ.\n",
    "- Применяю линейную функцию активации, так как мы ожидаем от модели возраст клиента и просто передаем входные значения без изменений.\n",
    "\n",
    "- **Эксперимент №1 функция потерь mse, функция активации relu**\n",
    "\n",
    "60/60 - 11s - loss: 92.1876 - mae: 7.1915\n",
    "Test MAE: 7.1915\n",
    "\n",
    "- **Эксперимент №2 функция потерь mse, функция активации None**\n",
    "\n",
    "60/60 - 11s - loss: 80.0059 - mae: 6.7166\n",
    "Test MAE: 6.71\n",
    "Таким образом, лучше заменить МАЕ в функции потерь на MSE (было с МАЕ: 60/60 - 11s - loss: 6.9105 - mae: 6.9094\n",
    "Test MAE: 6.9094)\n",
    "\n",
    "- **Эксперимент №3 функция потерь mse, функция активации  tanh**\n",
    "\n",
    "60/60 - 11s - loss: 1107.3302 - mae: 28.6162\n",
    "Test MAE: 28.6162\n",
    "\n",
    "- **Эксперимент №4 использование слоя GlobalAveragePooling2D вместо Flatten**\n",
    "\n",
    "60/60 - 11s - loss: 89.1308 - mae: 7.1782\n",
    "Test MAE: 7.1782\n",
    "\n",
    "- **Эксперимент №5 использование слоя GlobalAveragePooling2D и увеличение кол-во нейронов (в модели и добавим еще один слой с 512 нейронами)**\n",
    "\n",
    "60/60 - 11s - loss: 8.4558 - mae: 8.4772\n",
    "Test MAE: 8.4772\n",
    "\n",
    "- **Эксперимент №6 увеличение кол-ва эпох до 20**\n",
    "\n",
    "60/60 - 11s - loss: 5.8110 - mae: 5.8030\n",
    "Test MAE: 5.8030\n",
    "\n",
    "- **Эксперимент №7 первоночальная модель и увеличение кол-ва эпох до 20**\n",
    "60/60 - 10s - loss: 63.1681 - mae: 5.8968\n",
    "Test MAE: 5.8968\n",
    "\n",
    "**Вывод - в качестве функции активации в данном случае лучше использовать линейную функцию, а для функции потерь можно использовать mse, результат на 0,02 лучше, чем с МАЕ. Также качество модели удалось повысить до 5,80 (было 6.9094) с помощью замены слоя Flatten() на GlobalAveragePooling2D() и добавлением еще 512 нейронов.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Улучшенный код*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "def load_train(path):\n",
    "    labels = pd.read_csv(path + '/labels.csv')\n",
    "    datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 validation_split=0.25,\n",
    "                                 horizontal_flip=True)\n",
    "    train_datagen = datagen.flow_from_dataframe(dataframe=labels,\n",
    "                                                directory=path + '/final_files/',\n",
    "                                                x_col='file_name',\n",
    "                                                y_col='real_age',\n",
    "                                                target_size=(224, 224),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='raw',\n",
    "                                                subset='training',\n",
    "                                                seed=42)\n",
    "    return train_datagen\n",
    "\n",
    "def load_test(path):\n",
    "    labels = pd.read_csv(path + '/labels.csv')\n",
    "    datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 validation_split=0.25)\n",
    "    test_datagen = datagen.flow_from_dataframe(dataframe=labels,\n",
    "                                               directory=path + '/final_files/',\n",
    "                                               x_col='file_name',\n",
    "                                               y_col='real_age',\n",
    "                                               target_size=(224, 224),\n",
    "                                               batch_size=32,\n",
    "                                               class_mode='raw',\n",
    "                                               subset='validation',\n",
    "                                               seed=42)\n",
    "    return test_datagen\n",
    "   \n",
    "\n",
    "def create_model(input_shape):\n",
    "    resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation=None))\n",
    "    model.compile(loss='mae', optimizer=tf.keras.optimizers.Adam(lr=0.0001), metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=None, epochs=20,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "        \n",
    "    model.fit(train_data, \n",
    "              validation_data=test_data, \n",
    "              batch_size=batch_size, \n",
    "              epochs=epochs, \n",
    "              steps_per_epoch=steps_per_epoch, \n",
    "              validation_steps=validation_steps, \n",
    "              verbose=2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "Epoch 1/20\n",
    "2023-04-30 17:28:51.722512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2023-04-30 17:28:52.187542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "178/178 - 57s - loss: 10.7822 - mae: 10.7762 - val_loss: 17.2887 - val_mae: 17.2139\n",
    "Epoch 2/20\n",
    "178/178 - 44s - loss: 7.1273 - mae: 7.1270 - val_loss: 16.4334 - val_mae: 16.3713\n",
    "Epoch 3/20\n",
    "178/178 - 41s - loss: 6.0263 - mae: 6.0265 - val_loss: 14.7739 - val_mae: 14.7010\n",
    "Epoch 4/20\n",
    "178/178 - 56s - loss: 5.4816 - mae: 5.4817 - val_loss: 8.4559 - val_mae: 8.4506\n",
    "Epoch 5/20\n",
    "178/178 - 58s - loss: 4.9353 - mae: 4.9350 - val_loss: 6.8568 - val_mae: 6.8390\n",
    "Epoch 6/20\n",
    "178/178 - 61s - loss: 4.4186 - mae: 4.4187 - val_loss: 6.2662 - val_mae: 6.2492\n",
    "Epoch 7/20\n",
    "178/178 - 60s - loss: 4.0840 - mae: 4.0841 - val_loss: 7.3995 - val_mae: 7.3891\n",
    "Epoch 8/20\n",
    "178/178 - 61s - loss: 3.9761 - mae: 3.9764 - val_loss: 6.1792 - val_mae: 6.1651\n",
    "Epoch 9/20\n",
    "178/178 - 52s - loss: 3.6238 - mae: 3.6240 - val_loss: 6.7641 - val_mae: 6.7396\n",
    "Epoch 10/20\n",
    "178/178 - 41s - loss: 3.3873 - mae: 3.3875 - val_loss: 6.4637 - val_mae: 6.4594\n",
    "Epoch 11/20\n",
    "178/178 - 40s - loss: 3.2605 - mae: 3.2607 - val_loss: 6.1001 - val_mae: 6.0921\n",
    "Epoch 12/20\n",
    "178/178 - 42s - loss: 2.9840 - mae: 2.9840 - val_loss: 6.1655 - val_mae: 6.1643\n",
    "Epoch 13/20\n",
    "178/178 - 40s - loss: 2.9180 - mae: 2.9182 - val_loss: 5.9803 - val_mae: 5.9768\n",
    "Epoch 14/20\n",
    "178/178 - 40s - loss: 2.7838 - mae: 2.7838 - val_loss: 6.0886 - val_mae: 6.0833\n",
    "Epoch 15/20\n",
    "178/178 - 41s - loss: 2.6836 - mae: 2.6833 - val_loss: 5.8764 - val_mae: 5.8632\n",
    "Epoch 16/20\n",
    "178/178 - 41s - loss: 2.6091 - mae: 2.6092 - val_loss: 6.0117 - val_mae: 5.9932\n",
    "Epoch 17/20\n",
    "178/178 - 41s - loss: 2.5400 - mae: 2.5401 - val_loss: 5.8350 - val_mae: 5.8201\n",
    "Epoch 18/20\n",
    "178/178 - 41s - loss: 2.5454 - mae: 2.5455 - val_loss: 6.1822 - val_mae: 6.1772\n",
    "Epoch 19/20\n",
    "178/178 - 45s - loss: 2.3825 - mae: 2.3820 - val_loss: 6.2796 - val_mae: 6.2639\n",
    "Epoch 20/20\n",
    "178/178 - 60s - loss: 2.3612 - mae: 2.3613 - val_loss: 5.8110 - val_mae: 5.8030\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "60/60 - 11s - loss: 5.8110 - mae: 5.8030\n",
    "Test MAE: 5.8030\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ обученной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сетевой супермаркет «Хлеб-Соль» внедряет систему компьютерного зрения для обработки фотографий покупателей. Фотофиксация в прикассовой зоне поможет определять возраст клиентов, чтобы:\n",
    "\n",
    "- Анализировать покупки и предлагать товары, которые могут заинтересовать покупателей этой возрастной группы;\n",
    "\n",
    "- Контролировать добросовестность кассиров при продаже алкоголя.\n",
    "\n",
    "Для реализации задачи был использован датасет с фотографиями людей, всего изображений 7591. Самый распространенный возраст от 20 до 40 лет, реже встречаются люди в более старшем возрасте, от 60 лет, скорей всего на них модель будет ошибаться чаще, из-за недостатка данных. \n",
    "\n",
    "Далее мы использовали предобученную модель ResNet50, и дополнительнительные нейронный слои, в результате ряда эксперементов нам удалось добиться ошибки MAE на тестовой выборке 5,8 , что меньше 7, но недостаточно для достижения эталонного результата в 5,4. Чтоб минимизировать ошибку в дальнейшем необходима более сложная архитектура нейронной сети. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2714,
    "start_time": "2023-04-30T02:33:02.661Z"
   },
   {
    "duration": 98,
    "start_time": "2023-04-30T02:33:12.785Z"
   },
   {
    "duration": 96540,
    "start_time": "2023-04-30T02:33:23.104Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-30T02:34:59.647Z"
   },
   {
    "duration": 155,
    "start_time": "2023-04-30T02:34:59.655Z"
   },
   {
    "duration": 2152,
    "start_time": "2023-04-30T02:34:59.812Z"
   },
   {
    "duration": 15,
    "start_time": "2023-04-30T02:35:01.965Z"
   },
   {
    "duration": 3039,
    "start_time": "2023-04-30T13:47:23.892Z"
   },
   {
    "duration": 111,
    "start_time": "2023-04-30T13:47:26.934Z"
   },
   {
    "duration": 96217,
    "start_time": "2023-04-30T13:47:27.048Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-30T13:49:03.267Z"
   },
   {
    "duration": 214,
    "start_time": "2023-04-30T13:49:03.273Z"
   },
   {
    "duration": 2274,
    "start_time": "2023-04-30T13:49:03.489Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-30T13:49:05.766Z"
   },
   {
    "duration": 3072,
    "start_time": "2023-04-30T15:42:44.584Z"
   },
   {
    "duration": 146,
    "start_time": "2023-04-30T15:42:47.662Z"
   },
   {
    "duration": 138655,
    "start_time": "2023-04-30T15:42:47.811Z"
   },
   {
    "duration": 112,
    "start_time": "2023-04-30T15:45:06.468Z"
   },
   {
    "duration": 175,
    "start_time": "2023-04-30T17:30:36.644Z"
   },
   {
    "duration": 26,
    "start_time": "2023-04-30T17:31:07.472Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
